{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d49d65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision scikit-learn lgbt kagglehub numpy matplotlib tensorboard\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10cea080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets, models\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, classification_report\n",
    "from lgbt import lgbt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36f61c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/bolg4rin/simpson-dataset-fixed/versions/3\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"bolg4rin/simpson-dataset-fixed\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "363675f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init ():\n",
    "    model = models.resnet50(pretrained = True)\n",
    "    model.fc = nn.Linear(2048,42)\n",
    "    model = model.cuda()\n",
    "    loss = nn.CrossEntropyLoss().cuda()\n",
    "    optim = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=4, gamma=0.1)\n",
    "\n",
    "    return model, loss, optim, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50ff004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "original_train = datasets.ImageFolder(\n",
    "    root=f'{path}/the_simpson_dataset/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "original_test = datasets.ImageFolder(\n",
    "    root=f'{path}/the_simpson_dataset/test',\n",
    "    transform=val_test_transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(original_train))\n",
    "val_size = len(original_train) - train_size\n",
    "new_train, val_dataset = random_split(original_train, [train_size, val_size])\n",
    "\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "batch_size = 32\n",
    "pin_memory = torch.cuda.is_available()  # Enable only if GPU available\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    new_train, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    original_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "class_names = original_train.classes\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1aca80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, loss):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    validation_loss = 0\n",
    "\n",
    "    val_bar = lgbt(val_loader, desc=f'Validation')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_bar:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss_f = loss(outputs, labels)\n",
    "            validation_loss += loss_f.item()\n",
    "            predictions.extend(torch.argmax(outputs,dim=1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "                \n",
    "    macro_f1 = f1_score(targets, predictions, average='macro')\n",
    "\n",
    "    return macro_f1, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab07b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optim, scheduler):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = f\"logs/simpsons_{current_time}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_bar = lgbt(train_loader, desc=f'Train {epoch+1}/{num_epochs}', hero = \"unicorn\")\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_bar:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            # writer.add_graph(model, inputs)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            loss_f = loss(outputs, labels)\n",
    "            running_loss += loss_f.item()\n",
    "            loss_f.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        torch.save(model.state_dict(), f'simpsons_model/simpsons_scheduler{epoch}.pth')\n",
    "\n",
    "        macro_f1, validation_loss = valid_model(model, loss)\n",
    "        \n",
    "        running_loss /= len(train_loader)\n",
    "        validation_loss /= len(val_loader)\n",
    "        print(f'Epoch {epoch+1}:\\tLoss {running_loss}\\tValidation loss {validation_loss}\\tValidation F1 {(macro_f1*100):.2f}')\n",
    "\n",
    "        writer.add_scalar('Loss/train', running_loss, epoch)\n",
    "        writer.add_scalar('Loss/validation', validation_loss, epoch)\n",
    "        writer.add_scalar('F1/validation', macro_f1, epoch)\n",
    "\n",
    "        writer.add_scalar('Learning Rate', optim.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c2f2e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2214), started 6:40:02 ago. (Use '!kill 2214' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3041318f9dd8a49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3041318f9dd8a49\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bb08c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/ai_lab1/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/projects/ai_lab1/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ÑTrain 1/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [123.35s, 4.25it/s]  \u001b[m8it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [9.72s, 13.47it/s]  \u001b[m9it/s]  \u001b[m\n",
      "Epoch 1:\tLoss 0.6025746708046218\tValidation loss 0.19334294375046404\tValidation F1 74.10\n",
      "ü¶ÑTrain 2/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [118.91s, 4.41it/s]  \u001b[m6it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [9.96s, 13.16it/s]  \u001b[m8it/s]  \u001b[m\n",
      "Epoch 2:\tLoss 0.1136788714637994\tValidation loss 0.1705976187585647\tValidation F1 90.93\n",
      "ü¶ÑTrain 3/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [126.92s, 4.13it/s]  \u001b[m0it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [8.92s, 14.68it/s]  \u001b[m8it/s]  \u001b[m\n",
      "Epoch 3:\tLoss 0.04843436827861352\tValidation loss 0.13535216241143644\tValidation F1 91.49\n",
      "ü¶ÑTrain 4/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [116.20s, 4.51it/s]  \u001b[m1it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [8.96s, 14.62it/s]  \u001b[m4it/s]  \u001b[m\n",
      "Epoch 4:\tLoss 0.04803996824571429\tValidation loss 0.17692186974721272\tValidation F1 86.25\n",
      "ü¶ÑTrain 5/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [108.50s, 4.83it/s]  \u001b[m0it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [8.97s, 14.61it/s]  \u001b[m0it/s]  \u001b[m\n",
      "Epoch 5:\tLoss 0.021012260772968566\tValidation loss 0.10073446142238401\tValidation F1 93.76\n",
      "ü¶ÑTrain 6/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [106.74s, 4.91it/s]  \u001b[m1it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [9.00s, 14.55it/s]  \u001b[m4it/s]  \u001b[m\n",
      "Epoch 6:\tLoss 0.006432652239897022\tValidation loss 0.09394958926336343\tValidation F1 94.37\n",
      "ü¶ÑTrain 7/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [108.62s, 4.82it/s]  \u001b[m0it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [9.66s, 13.57it/s]  \u001b[m5it/s]  \u001b[m\n",
      "Epoch 7:\tLoss 0.004425097267507338\tValidation loss 0.08960259913130066\tValidation F1 94.94\n",
      "ü¶ÑTrain 8/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [114.98s, 4.56it/s]  \u001b[m0it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [9.60s, 13.64it/s]  \u001b[m7it/s]  \u001b[m\n",
      "Epoch 8:\tLoss 0.0033980529749910843\tValidation loss 0.08816604152431122\tValidation F1 94.55\n",
      "ü¶ÑTrain 9/10  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [116.97s, 4.48it/s]  \u001b[m9it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [11.47s, 11.42it/s]  \u001b[mit/s]  \u001b[m\n",
      "Epoch 9:\tLoss 0.0026988866944201487\tValidation loss 0.08867911386587088\tValidation F1 95.10\n",
      "ü¶ÑTrain 10/10 :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[524/524] [120.38s, 4.35it/s]  \u001b[m5it/s]  \u001b[m\n",
      "üåàValidation  :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[131/131] [10.03s, 13.06it/s]  \u001b[mit/s]  \u001b[m\n",
      "Epoch 10:\tLoss 0.002744616625446405\tValidation loss 0.08796626108610568\tValidation F1 94.84\n"
     ]
    }
   ],
   "source": [
    "simpsons_model, loss_func, optimizer, scheduler = model_init()\n",
    "train_model(simpsons_model, loss_func, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acd215d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    preds = []\n",
    "    targets = []\n",
    "    class_preds = []\n",
    "    class_targets = []\n",
    "    for i in range(42):\n",
    "        class_preds.append([])\n",
    "        class_targets.append([])\n",
    "\n",
    "    test_bar = lgbt(test_loader, desc='Test', hero = 'kitten')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_bar:\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            for i in range (len(target)):\n",
    "                class_code = target[i]\n",
    "                class_targets[class_code].append(class_code.cpu().numpy())\n",
    "                class_preds[class_code].append(pred[i].cpu().numpy())\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            targets.extend(target.cpu().numpy())\n",
    "\n",
    "    macro_f1 = f1_score(targets, preds, average='macro')\n",
    "    accuracy = accuracy_score(targets,preds)\n",
    "    print(f'Macro F1: {(macro_f1*100):.2f}%')\n",
    "    print(f'Accuracy: {(accuracy*100):.2f}%')\n",
    "\n",
    "    for i in range(len(class_preds)):\n",
    "        acc = accuracy_score(class_preds[i], class_targets[i])\n",
    "        print(f'{original_test.classes[i]} accuracy: {(acc*100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79b40a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê±Test        :\u001b[35m100% \u001b[31m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[38;5;214m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[33m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[32m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[36m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[34m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã‚ñã\u001b[35m[14/14] [1.23s, 11.40it/s]  \u001b[mit/s]  \u001b[m\n",
      "Macro F1: 91.63%\n",
      "Accuracy: 92.05%\n",
      "abraham_grampa_simpson accuracy: 100.00%\n",
      "agnes_skinner accuracy: 40.00%\n",
      "apu_nahasapeemapetilon accuracy: 100.00%\n",
      "barney_gumble accuracy: 70.00%\n",
      "bart_simpson accuracy: 100.00%\n",
      "carl_carlson accuracy: 100.00%\n",
      "charles_montgomery_burns accuracy: 100.00%\n",
      "chief_wiggum accuracy: 90.91%\n",
      "cletus_spuckler accuracy: 100.00%\n",
      "comic_book_guy accuracy: 100.00%\n",
      "disco_stu accuracy: 80.00%\n",
      "edna_krabappel accuracy: 100.00%\n",
      "fat_tony accuracy: 90.00%\n",
      "gil accuracy: 90.00%\n",
      "groundskeeper_willie accuracy: 80.00%\n",
      "homer_simpson accuracy: 100.00%\n",
      "kent_brockman accuracy: 100.00%\n",
      "krusty_the_clown accuracy: 100.00%\n",
      "lenny_leonard accuracy: 100.00%\n",
      "lionel_hutz accuracy: 100.00%\n",
      "lisa_simpson accuracy: 100.00%\n",
      "maggie_simpson accuracy: 90.00%\n",
      "marge_simpson accuracy: 100.00%\n",
      "martin_prince accuracy: 90.00%\n",
      "mayor_quimby accuracy: 90.91%\n",
      "milhouse_van_houten accuracy: 100.00%\n",
      "miss_hoover accuracy: 80.00%\n",
      "moe_szyslak accuracy: 100.00%\n",
      "ned_flanders accuracy: 100.00%\n",
      "nelson_muntz accuracy: 100.00%\n",
      "otto_mann accuracy: 100.00%\n",
      "patty_bouvier accuracy: 80.00%\n",
      "principal_skinner accuracy: 100.00%\n",
      "professor_john_frink accuracy: 80.00%\n",
      "rainier_wolfcastle accuracy: 70.00%\n",
      "ralph_wiggum accuracy: 90.00%\n",
      "selma_bouvier accuracy: 100.00%\n",
      "sideshow_bob accuracy: 90.91%\n",
      "sideshow_mel accuracy: 100.00%\n",
      "snake_jailbird accuracy: 70.00%\n",
      "troy_mcclure accuracy: 90.00%\n",
      "waylon_smithers accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "test_model(simpsons_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
